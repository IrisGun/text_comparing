{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Check type of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+84987654321\n"
     ]
    }
   ],
   "source": [
    "## Check phone number \n",
    "\n",
    "import re\n",
    "\n",
    "def is_vietnamese_phone_number(number):\n",
    "    \"\"\"Validates if a given string is a Vietnamese phone number.\n",
    "\n",
    "    Args:\n",
    "        number (str): The phone number to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number is valid, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove non-numeric characters\n",
    "    cleaned_number = re.sub(r\"\\D\", \"\", number)\n",
    "\n",
    "    # Check for valid lengths and prefixes\n",
    "    return bool(re.match(r\"^(0|\\+84|84|0084)([3-9]{1}|[1][2-9])\\d{8}$\", cleaned_number))\n",
    "\n",
    "\n",
    "def convert_to_10_digits(number):\n",
    "    \"\"\"Converts an 11-digit Vietnamese phone number to 10 digits based on the provided rules.\n",
    "\n",
    "    Args:\n",
    "        number (str): The 11-digit phone number.\n",
    "\n",
    "    Returns:\n",
    "        str: The converted 10-digit phone number or the original number if not applicable.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_number = re.sub(r\"\\D\", \"\", number)\n",
    "    if len(cleaned_number) != 11:\n",
    "        return number\n",
    "\n",
    "    # Convert old format of VNese phone number into 10 digit format\n",
    "    prefix = cleaned_number[:3]\n",
    "    if prefix in [\"0120\", \"0121\", \"0122\", \"0126\", \"0128\"]:\n",
    "        return \"07\" + cleaned_number[3:]\n",
    "    elif prefix in [\"0123\", \"0124\", \"0125\", \"0127\", \"0129\"]:\n",
    "        return \"08\" + cleaned_number[3:]\n",
    "    elif prefix in [\"0162\", \"0163\", \"0164\", \"0165\", \"0166\", \"0167\", \"0168\", \"0169\"]:\n",
    "        return \"03\" + cleaned_number[3:]\n",
    "    elif prefix in [\"0186\", \"0188\"]:\n",
    "        return \"05\" + cleaned_number[3:]\n",
    "    elif prefix == \"0199\":\n",
    "        return \"059\" + cleaned_number[4:]\n",
    "    else:\n",
    "        return number\n",
    "\n",
    "# Example usage:\n",
    "phone_number = \"+84987654321\"\n",
    "if is_vietnamese_phone_number(phone_number):\n",
    "    converted_number = convert_to_10_digits(phone_number)\n",
    "    print(converted_number)  # Output: 987654321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DataValidator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def validate_phone_number(self, phone_number):\n",
    "        # A basic phone number validation, you might want to refine based on specific formats\n",
    "        phone_pattern = r\"^\\d{10,11}$\"  # Adjust pattern as needed\n",
    "        return bool(re.match(phone_pattern, phone_number))\n",
    "\n",
    "    def validate_email(self, email):\n",
    "        email_pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "        return bool(re.match(email_pattern, email))\n",
    "\n",
    "    def validate_name(self, name):\n",
    "        # A basic check for non-empty strings\n",
    "        return bool(name.strip())\n",
    "\n",
    "    def validate_and_clean(self, data):\n",
    "        \"\"\"Validates and cleans the given data.\n",
    "\n",
    "        Args:\n",
    "            data (dict): A dictionary containing customer information.\n",
    "\n",
    "        Returns:\n",
    "            dict: A validated and cleaned dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        cleaned_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key == 'phone_number':\n",
    "                if self.validate_phone_number(value):\n",
    "                    cleaned_data[key] = value\n",
    "                else:\n",
    "                    cleaned_data[key] = None\n",
    "            elif key == 'email':\n",
    "                if self.validate_email(value):\n",
    "                    cleaned_data[key] = value\n",
    "                else:\n",
    "                    cleaned_data[key] = None\n",
    "            else:\n",
    "                cleaned_data[key] = value.strip()  # Basic cleaning for other fields\n",
    "\n",
    "        return cleaned_data\n",
    "\n",
    "# Example usage:\n",
    "customer_data = {\n",
    "    'id': '0001',\n",
    "    'phone_number': '0987654321',\n",
    "    'name': 'Nguyễn Văn A',\n",
    "    'email': 'nguyenvanA@gmail.com'\n",
    "}\n",
    "\n",
    "validated_data = DataValidator().validate_and_clean(customer_data)\n",
    "print(validated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Match "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Compare 2 separate texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_text_similarity(text1, text2):\n",
    "    \"\"\"Tính toán độ tương đồng giữa hai văn bản.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): Văn bản thứ nhất.\n",
    "        text2 (str): Văn bản thứ hai.\n",
    "\n",
    "    Returns:\n",
    "        float: Độ tương đồng giữa hai văn bản, trong khoảng từ 0 đến 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tiền xử lý văn bản: Loại bỏ stop words, stemming\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    def preprocess(text):\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    text1 = preprocess(text1)\n",
    "    text2 = preprocess(text2)\n",
    "\n",
    "    # Tạo vector đặc trưng cho từng văn bản\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "    # Tính toán độ tương đồng cosine\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)[0][1]\n",
    "\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5031026124151314\n"
     ]
    }
   ],
   "source": [
    "text1 = \"This is a sample sentence\"\n",
    "text2 = \"This sentence is an example\"\n",
    "similarity = calculate_text_similarity(text1, text2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5031026124151314"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = 'Bùi Văn Hải'\n",
    "text_2 = 'Bùi Vân Hải'\n",
    "calculate_text_similarity(text_1, text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. All methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.util import ngrams\n",
    "from Levenshtein import distance\n",
    "from gensim.models import Word2Vec\n",
    "from ot import emd2  # Assuming ot is installed\n",
    "\n",
    "\n",
    "def calculate_similarities(text1, text2):\n",
    "    \"\"\"Tính toán độ tương đồng giữa hai văn bản bằng nhiều phương pháp.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): Văn bản thứ nhất.\n",
    "        text2 (str): Văn bản thứ hai.\n",
    "\n",
    "    Returns:\n",
    "        dict: Một dictionary chứa các phương pháp và giá trị độ tương đồng tương ứng.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tiền xử lý văn bản\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    def preprocess(text):\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "        return words\n",
    "\n",
    "    tokens1 = preprocess(text1)\n",
    "    tokens2 = preprocess(text2)\n",
    "\n",
    "    # Tính toán các loại độ tương đồng\n",
    "    similarities = {}\n",
    "\n",
    "    # Jaccard similarity\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    similarities['Jaccard'] = len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "    # Levenshtein distance\n",
    "    similarities['Levenshtein'] = 1 - (distance(text1, text2) / max(len(text1), len(text2)))\n",
    "\n",
    "    # Cosine similarity\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    similarities['Cosine'] = cosine_similarity(tfidf_matrix)[0][1]\n",
    "\n",
    "    # N-gram overlap\n",
    "    bigrams1 = list(ngrams(tokens1, 2))\n",
    "    bigrams2 = list(ngrams(tokens2, 2))\n",
    "    similarities['Bigram overlap'] = len(set(bigrams1).intersection(set(bigrams2))) / len(set(bigrams1).union(bigrams2))\n",
    "\n",
    "    # ... Thêm các phương pháp khác như WMD, embedding-based similarity ...\n",
    "    # Word Mover's Distance (WMD)\n",
    "    model = Word2Vec([tokens1, tokens2], min_count=1)\n",
    "    similarities['WMD'] = model.wv.wmdistance(tokens1, tokens2)\n",
    "\n",
    "    # Embedding-based similarity (e.g., using Word2Vec)\n",
    "    word_vectors = model.wv\n",
    "    vector1 = sum(word_vectors[word] for word in tokens1) / len(tokens1)\n",
    "    vector2 = sum(word_vectors[word] for word in tokens2) / len(tokens2)\n",
    "    similarities['Embedding'] = cosine_similarity([vector1], [vector2])[0][0]\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jaccard': 0.5, 'Levenshtein': 0.33333333333333337, 'Cosine': 0.5101490193104813, 'Bigram overlap': 0.0, 'WMD': 0.47457931422164573, 'Embedding': 0.6445959}\n",
      "0.4104429313175069\n"
     ]
    }
   ],
   "source": [
    "text1 = \"This is a sample sentence\"\n",
    "text2 = \"This sentence is an example\"\n",
    "similarity = calculate_similarities(text1, text2)\n",
    "print(similarity)\n",
    "print(sum(similarity.values())/len(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jaccard': 0.5, 'Levenshtein': 0.9090909090909091, 'Cosine': 0.5031026124151314, 'Bigram overlap': 0.0, 'WMD': 0.47457931422164573, 'Embedding': 0.6445959}\n",
      "0.5052281261278779\n"
     ]
    }
   ],
   "source": [
    "text1 = 'Bùi Văn Hải'\n",
    "text2 = 'Bùi Vân Hải'\n",
    "similarity = calculate_similarities(text1, text2)\n",
    "print(similarity)\n",
    "print(sum(similarity.values())/len(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Compare 2 records (as 2 vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def compare_records(record1, record2):\n",
    "    \"\"\"Compare similarity between 2 records syntaxtically, not semantically.\n",
    "\n",
    "    Args:\n",
    "        record1 (tuple): First record Ex: (id, phone_no, name, email).\n",
    "        record2 (tuple): Second record Ex: (id, phone_no, name, email).\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity between 2 records\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the input data\n",
    "    def preprocess_text(text):\n",
    "        # Preprocess text depending on the type it needed\n",
    "        text = re.sub(r'\\D', '', text)\n",
    "        # ... Other preprocessing if needed for each type of data\n",
    "        # (Ex: stemming, lemmatization)\n",
    "        return text\n",
    "\n",
    "    # Create vector for each records\n",
    "    vector_data = []\n",
    "    for record in [record1, record2]:\n",
    "        vector_data.append(' '.join([\n",
    "            preprocess_text(record[1]),\n",
    "            preprocess_text(record[2]),\n",
    "            record[3]\n",
    "        ]))\n",
    "        print(record)\n",
    "\n",
    "    print(vector_data)\n",
    "\n",
    "    # Tính toán TF-IDF và cosine similarity\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(vector_data)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)[0][1]\n",
    "\n",
    "    print(tfidf_matrix)\n",
    "\n",
    "    # Get the feature names (words)\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Get the TF-IDF values for each document\n",
    "    tfidf_values = tfidf_matrix.toarray()\n",
    "\n",
    "    # Create a DataFrame to visualize the results\n",
    "    df = pd.DataFrame(tfidf_values, columns=words)\n",
    "    print(df)\n",
    "\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0001', '123456789', 'John smith', 'john@gmail.com')\n",
      "('0001', '0123456789', 'john sMITH', 'john@gmail.com')\n",
      "['123456789  john@gmail.com', '0123456789  john@gmail.com']\n",
      "  (0, 2)\t0.44832087319911734\n",
      "  (0, 3)\t0.44832087319911734\n",
      "  (0, 4)\t0.44832087319911734\n",
      "  (0, 1)\t0.6300993445179441\n",
      "  (1, 0)\t0.6300993445179441\n",
      "  (1, 2)\t0.44832087319911734\n",
      "  (1, 3)\t0.44832087319911734\n",
      "  (1, 4)\t0.44832087319911734\n",
      "   0123456789  123456789       com     gmail      john\n",
      "0    0.000000   0.630099  0.448321  0.448321  0.448321\n",
      "1    0.630099   0.000000  0.448321  0.448321  0.448321\n",
      "0.6029748160380572\n"
     ]
    }
   ],
   "source": [
    "record1 = ('0001', \"123456789\", \"John smith\", \"john@gmail.com\")\n",
    "record2 = ('0001', \"0123456789\", \"john sMITH\", \"john@gmail.com\")\n",
    "\n",
    "similarity = compare_records(record1, record2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
